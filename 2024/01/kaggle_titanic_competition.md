# [kaggle机器学习竞赛](/2024/01/kaggle_titanic_competition.md)

使用泰坦尼克号乘客的数据(姓名、年龄、票价等)来预测谁会幸存

submission.csv的格式是两列，第一列是乘客id，第二列是是否存储布尔值

pip install kaggle

kaggle competitions download -c titanic

OSError: Could not find kaggle.json

需要在kaggle官方生成个api json放到 $HOME/.kaggle

## 特征工程

> 我对数据集的分析是，首先上船位置embarked这列肯定是没有用的是噪声数据可排除，船难跟上船位置关联性很低，然后我可能偏向于 是否是成年男性这样的特征的权重更大，你是怎么分析泰坦尼克数据集每列的权重的

对于泰坦尼克号数据集，每列的权重分析实际上是通过特征工程和机器学习模型来确定的。以下是分析过程中可能采取的一些步骤：

1. **理解数据集**：首先，你需要理解每列数据的含义以及它们可能与生存结果的关系。比如，`Sex`（性别）和`Age`（年龄）通常被认为是重要的特征，因为历史资料表明妇女和儿童有更高的生存率。

2. **数据可视化**：使用图表来观察不同特征与生存率之间的关系。例如，可以使用条形图查看不同登船地点（`Embarked`）的乘客生存率是否有显著差异。

3. **相关性分析**：计算特征之间的相关系数，以及特征与生存结果之间的相关性。这有助于识别潜在的关键特征。

4. **特征工程**：转换或创建新特征，以便更好地捕捉预测生存率的因素。例如，可以创建一个新的特征来表明乘客是否是成年男性。

5. **构建模型**：使用不同的机器学习算法构建预测模型，并通过交叉验证来评估它们的性能。

6. **特征重要性评估**：一旦模型被训练，可以使用模型本身来评估特征的重要性。例如，决策树和随机森林模型可以提供直接的特征重要性估计。

7. **迭代优化**：根据模型的反馈调整特征工程，去掉或创建新的特征，然后重新训练模型，直至达到满意的准确度。

关于船舱位置（`Embarked`）的特征，虽然乍看可能与生存率关联性不大，但实际上可能存在一些间接关联。例如，某些船舱可能更靠近救生艇，或者船舱位置可能与乘客的社会经济状态相关，而后者可能影响了他们的生存率。因此，在没有具体证据表明某个特征完全无关之前，直接排除任何特征可能并非最佳实践。

在实际操作中，应该在数据探索阶段保持开放的心态，让数据指导你的决策。通过逐步的分析和模型验证，来确定每个特征的实际重要性。

## 模型选择

> 我对python3 sklearn比较熟悉点，kaggle titanic train data 适合用怎样的模型？我数学功底很差只熟悉线性建模

如果您的数学基础不是很扎实，而且您熟悉线性模型，那么可以从简单的模型开始，并逐步尝试更复杂的模型。以下是几种适用于Kaggle Titanic数据集的机器学习模型，从简单到复杂排列：

1. **逻辑回归（Logistic Regression）**：这是一种广泛使用的线性模型，适用于二分类问题，比如Titanic生存预测。尽管简单，但逻辑回归在许多二分类问题上表现都相当不错。

2. **决策树（Decision Tree）**：决策树是一种基本的非线性模型，它通过一系列规则来进行预测。它们易于理解和解释，可以处理特征间的非线性关系。

3. **随机森林（Random Forest）**：随机森林是一种集成学习方法，它构建多个决策树并取它们的平均预测值。这种方法通常能提高模型的性能和泛化能力。

4. **支持向量机（Support Vector Machine, SVM）**：SVM是一种强大的分类器，它在数据集中找到最佳的边界线（或超平面）来区分不同的类别。对于非线性问题，可以使用核技巧来使数据在更高维度空间中线性可分。

5. **梯度提升决策树（Gradient Boosting Decision Trees, GBDT）**：GBDT是一种集成学习技术，它结合了多个决策树模型的预测。模型通过迭代地改进来增强性能，通常在各种数据集上都能达到很高的准确率。

6. **K-最近邻（K-Nearest Neighbors, KNN）**：KNN是一种基于实例的学习，它根据最近的K个邻居的类别来预测新数据点的类别。

7. **朴素贝叶斯（Naive Bayes）**：朴素贝叶斯分类器基于贝叶斯定理，它假设特征之间相互独立。尽管这个假设在现实中往往不成立，但朴素贝叶斯在很多情况下仍然工作得很好。

由于您熟悉线性模型，可以从逻辑回归开始，它是解决二分类问题的一个很好的起点。在Python中，您可以使用scikit-learn库来实现这些模型。逻辑回归模型可以这样创建：

```python
from sklearn.linear_model import LogisticRegression

# 创建逻辑回归模型
model = LogisticRegression()

# 训练模型
model.fit(X_train, y_train)

# 进行预测
predictions = model.predict(X_test)
```

在这里，`X_train` 是训练数据集的特征变量，`y_train` 是训练数据集的目标变量（即生存与否）。`X_test` 是测试数据集的特征变量。

记得在使用模型之前，您需要进行数据预处理，包括处理缺失值、转换类别变量（如使用独热编码），以及特征缩放等。

随着您对数据和模型的进一步理解，您可以尝试使用更复杂的模型，并对它们进行调优以获得更好的结果。
